# ğŸ“ˆ Stock Market Forecasting with GAN

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-blue)](https://mlflow.org/)

> **A production-ready, state-of-the-art GAN-based system for stock market forecasting using deep learning, featuring LSTM generators, CNN discriminators, and comprehensive MLOps integration.**

---

## ğŸŒŸ Key Features

### **Multi-Technology Stack**
- **PyTorch** - Deep learning framework with CUDA acceleration
- **MLflow** - Experiment tracking and model registry
- **FastAPI** - Production-ready REST API
- **Optuna** - Bayesian hyperparameter optimization
- **PostgreSQL/TimescaleDB** - Time-series data storage

### **Advanced Architecture**
- **Wasserstein GAN with Gradient Penalty (WGAN-GP)** - Stable training with Lipschitz constraint
- **LSTM Generator** - Time-series generation with attention mechanism
- **CNN Discriminator** - 1D convolutional network for sequence classification
- **Multi-source Feature Engineering** - Technical indicators, Fourier transforms, sentiment analysis

### **Production-Ready**
- âœ… Modular, extensible codebase with proper abstractions
- âœ… Comprehensive configuration management (YAML)
- âœ… Structured logging and monitoring
- âœ… Unit tests and integration tests
- âœ… Docker containerization
- âœ… CI/CD pipeline with GitHub Actions
- âœ… Detailed inline documentation

---

## ğŸ“Š Project Overview

This project implements a Generative Adversarial Network (GAN) for predicting stock market movements. Unlike traditional time-series forecasting methods, GANs can capture complex, non-linear patterns in financial data by learning the underlying distribution of stock price movements.

### **Why GAN for Stock Market Forecasting?**

1. **Distribution Learning**: GANs learn the actual distribution of price movements, not just point predictions
2. **Adversarial Training**: The discriminator acts as a sophisticated validator, ensuring realistic predictions
3. **Feature Extraction**: Multi-layered networks automatically discover relevant patterns
4. **Handling Non-Stationarity**: GANs can adapt to changing market regimes

### **Architecture Diagram**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Sources   â”‚
â”‚  â€¢ OHLCV Data   â”‚
â”‚  â€¢ Indices      â”‚
â”‚  â€¢ Currencies   â”‚
â”‚  â€¢ Sentiment    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing   â”‚
â”‚ â€¢ Cleaning      â”‚
â”‚ â€¢ Normalization â”‚
â”‚ â€¢ Alignment     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Eng.    â”‚
â”‚ â€¢ Technical     â”‚
â”‚ â€¢ Fourier       â”‚
â”‚ â€¢ ARIMA         â”‚
â”‚ â€¢ Lags/Rolling  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Generator     â”‚â—„â”€â”€â”€â”€â”€â”¤  Random Noise   â”‚
â”‚    (LSTM)       â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Generated Sequences
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Discriminator   â”‚
â”‚     (CNN)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Real/Fake Score
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Wasserstein     â”‚
â”‚ Loss + GP       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Getting Started

### **Prerequisites**

- Python 3.9+
- CUDA-capable GPU (GTX 3050Ti or better recommended)
- 8GB+ RAM
- Git

### **Installation**

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/Stock-Market-Forecasting-with-GAN.git
cd Stock-Market-Forecasting-with-GAN
```

2. **Create virtual environment**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Setup CUDA (for GPU training)**
```bash
# Verify CUDA installation
python -c "import torch; print(torch.cuda.is_available())"
```

---

## ğŸ’» Usage

### **1. Data Collection**

```python
from src.data.collectors import DataCollector

collector = DataCollector(
    ticker="GS",
    start_date="2010-01-01",
    end_date="2023-12-31"
)

primary_data, correlated_data = collector.fetch_all_data()
```

### **2. Train the Model**

```bash
python scripts/train.py \
    --model-config configs/model_config.yaml \
    --training-config configs/training_config.yaml \
    --data-config configs/data_config.yaml
```

### **3. Monitor Training with MLflow**

```bash
mlflow ui
# Open browser at http://localhost:5000
```

### **4. Hyperparameter Optimization**

```bash
python scripts/optimize.py --n-trials 100
```

### **5. Make Predictions**

```bash
python scripts/predict.py \
    --model-path models/final/final_model.pt \
    --input-data data/test.csv \
    --output predictions.csv
```

---

## ğŸ“ Project Structure

```
Stock-Market-Forecasting-with-GAN/
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ data/                     # Data processing modules
â”‚   â”‚   â”œâ”€â”€ collectors.py         # Data collection from APIs
â”‚   â”‚   â”œâ”€â”€ preprocessors.py      # Data cleaning & normalization
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py # Technical indicators & features
â”‚   â”‚   â””â”€â”€ datasets.py           # PyTorch Dataset classes
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                   # Model architectures
â”‚   â”‚   â”œâ”€â”€ generator.py          # LSTM Generator
â”‚   â”‚   â”œâ”€â”€ discriminator.py      # CNN Discriminator
â”‚   â”‚   â”œâ”€â”€ gan.py                # WGAN-GP implementation
â”‚   â”‚   â””â”€â”€ components.py         # Shared components
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                 # Training utilities
â”‚   â”‚   â”œâ”€â”€ trainer.py            # Training loop
â”‚   â”‚   â”œâ”€â”€ losses.py             # Custom loss functions
â”‚   â”‚   â””â”€â”€ callbacks.py          # Training callbacks
â”‚   â”‚
â”‚   â”œâ”€â”€ optimization/             # Hyperparameter optimization
â”‚   â”‚   â”œâ”€â”€ hyperparameter_search.py
â”‚   â”‚   â””â”€â”€ schedulers.py
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/                # Prediction & API
â”‚   â”‚   â”œâ”€â”€ predictor.py          # Prediction logic
â”‚   â”‚   â””â”€â”€ api.py                # FastAPI endpoints
â”‚   â”‚
â”‚   â””â”€â”€ utils/                    # Utilities
â”‚       â”œâ”€â”€ logger.py             # Logging setup
â”‚       â”œâ”€â”€ metrics.py            # Evaluation metrics
â”‚       â””â”€â”€ visualization.py      # Plotting functions
â”‚
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â”œâ”€â”€ model_config.yaml         # Model architecture
â”‚   â”œâ”€â”€ training_config.yaml      # Training parameters
â”‚   â”œâ”€â”€ data_config.yaml          # Data sources
â”‚   â””â”€â”€ inference_config.yaml     # API configuration
â”‚
â”œâ”€â”€ data/                         # Data directory
â”‚   â”œâ”€â”€ raw/                      # Raw downloaded data
â”‚   â”œâ”€â”€ processed/                # Processed features
â”‚   â””â”€â”€ predictions/              # Model outputs
â”‚
â”œâ”€â”€ models/                       # Saved models
â”‚   â”œâ”€â”€ checkpoints/              # Training checkpoints
â”‚   â””â”€â”€ final/                    # Production models
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_eda.ipynb              # Exploratory analysis
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_experiments.ipynb
â”‚   â””â”€â”€ 04_results_analysis.ipynb
â”‚
â”œâ”€â”€ scripts/                      # Executable scripts
â”‚   â”œâ”€â”€ train.py                  # Main training script
â”‚   â”œâ”€â”€ optimize.py               # Hyperparameter optimization
â”‚   â”œâ”€â”€ predict.py                # Run predictions
â”‚   â””â”€â”€ download_data.py          # Data download script
â”‚
â”œâ”€â”€ tests/                        # Unit tests
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ deployment/                   # Deployment files
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .github/                      # CI/CD
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                # GitHub Actions
â”‚
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ setup.py                      # Package setup
â””â”€â”€ LICENSE                       # MIT License
```

---

## ğŸ”§ Configuration

All configurations are in YAML format for easy modification:

### **Model Configuration** (`configs/model_config.yaml`)
- Generator architecture (LSTM layers, hidden dimensions)
- Discriminator architecture (CNN layers, filters)
- WGAN-GP parameters (lambda_gp, n_critic)

### **Training Configuration** (`configs/training_config.yaml`)
- Training parameters (epochs, batch_size, learning_rate)
- Data split ratios
- Checkpoint settings
- Early stopping parameters

### **Data Configuration** (`configs/data_config.yaml`)
- Stock ticker and date range
- Correlated assets to include
- Feature engineering options
- Preprocessing methods

---

## ğŸ“Š Features Engineering

### **Technical Indicators**
- Moving Averages (MA7, MA21, MA50)
- Exponential Moving Averages (EMA12, EMA26)
- MACD (Moving Average Convergence Divergence)
- RSI (Relative Strength Index)
- Bollinger Bands
- ATR (Average True Range)
- OBV (On-Balance Volume)
- Momentum indicators

### **Advanced Features**
- **Fourier Transforms**: Extract trend components (3, 6, 9, 50 components)
- **ARIMA Predictions**: Use traditional forecasting as features
- **Lag Features**: Historical values (1, 2, 3, 5, 10 days)
- **Rolling Statistics**: Mean, std, min, max over various windows

### **Correlated Assets**
- Financial institutions (JPM, MS, BAC, C, WFC)
- Market indices (S&P 500, Dow Jones, NASDAQ, FTSE, Nikkei)
- Volatility (VIX)
- Currencies (EUR/USD, GBP/USD, JPY/USD)
- Commodities (Gold, Oil)

---

## ğŸ§  Model Architecture

### **Generator (LSTM)**
```python
LSTMGenerator(
    noise_dim=100,       # Random noise input
    hidden_dim=256,      # LSTM hidden units
    num_layers=2,        # Number of LSTM layers
    n_features=112,      # Number of output features
    sequence_length=20,  # Length of generated sequences
    dropout=0.2          # Dropout rate
)
```

### **Discriminator (CNN)**
```python
CNNDiscriminator(
    n_features=112,          # Input features
    sequence_length=20,      # Sequence length
    base_filters=64,         # Initial conv filters
    num_conv_layers=3,       # Number of conv layers
    fc_hidden_dim=128,       # FC layer dimension
    dropout=0.3              # Dropout rate
)
```

### **Loss Function**
- **Wasserstein Loss**: More stable than vanilla GAN
- **Gradient Penalty**: Enforces Lipschitz constraint
- **Formula**: `L_D = E[D(fake)] - E[D(real)] + Î»_GP * GP`

---

## ğŸ“ˆ Training Process

1. **Data Collection**: Fetch historical stock data and correlated assets
2. **Preprocessing**: Clean, normalize, and align data
3. **Feature Engineering**: Create 100+ features from raw data
4. **Model Training**: Train WGAN-GP with:
   - 5 discriminator updates per generator update
   - Gradient penalty for stability
   - Learning rate scheduling
   - Mixed precision training (faster on GPU)
5. **Validation**: Monitor Wasserstein distance and loss metrics
6. **Checkpointing**: Save models every N epochs
7. **MLflow Tracking**: Log all metrics and hyperparameters

---

## ğŸ¯ Evaluation Metrics

- **Mean Squared Error (MSE)**
- **Root Mean Squared Error (RMSE)**
- **Mean Absolute Error (MAE)**
- **Mean Absolute Percentage Error (MAPE)**
- **RÂ² Score**
- **Directional Accuracy** - % of correct up/down predictions
- **Sharpe Ratio** - Risk-adjusted returns
- **Maximum Drawdown**
- **Wasserstein Distance** - Quality of generated samples

---

## ğŸš¢ Deployment

### **Docker Deployment**

```bash
# Build image
docker build -t stock-gan:latest -f deployment/Dockerfile .

# Run container
docker run -p 8000:8000 --gpus all stock-gan:latest
```

### **FastAPI Service**

```bash
uvicorn src.inference.api:app --host 0.0.0.0 --port 8000
```

Access API documentation at `http://localhost:8000/docs`

---

## ğŸ”¬ Hyperparameter Optimization

The project uses Optuna for Bayesian hyperparameter optimization:

```python
# Optimizable parameters:
- learning_rate (1e-5 to 1e-3)
- batch_size (32, 64, 128)
- hidden_dim (128, 256, 512)
- num_layers (1, 2, 3, 4)
- dropout (0.1 to 0.5)
- lambda_gp (1 to 20)
```

Run optimization:
```bash
python scripts/optimize.py --n-trials 100 --study-name stock_gan_optimization
```

---

## ğŸ“ TODO / Future Enhancements

- [ ] Add sentiment analysis from news APIs (FinBERT)
- [ ] Implement attention mechanism in generator
- [ ] Add transformer-based discriminator
- [ ] Multi-asset prediction (portfolio optimization)
- [ ] Reinforcement learning for trading strategies
- [ ] Real-time inference pipeline
- [ ] Kubernetes deployment manifests
- [ ] A/B testing framework
- [ ] Model interpretability (SHAP values)
- [ ] Streaming data ingestion (Kafka)

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

Please ensure:
- Code follows PEP 8 style guide
- All tests pass
- Documentation is updated
- Commit messages are clear

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## âš ï¸ Disclaimer

**THIS SOFTWARE IS FOR EDUCATIONAL AND RESEARCH PURPOSES ONLY.**

- This is NOT financial advice
- Past performance does not guarantee future results
- Trading stocks carries substantial risk
- The authors are not responsible for any financial losses
- Always consult with a licensed financial advisor
- Use at your own risk

---

## ğŸ™ Acknowledgments

- Inspired by research in GAN-based time-series forecasting
- Built with PyTorch, MLflow, and FastAPI
- Special thanks to the open-source community

---

## ğŸ“§ Contact

**Your Name**
- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Your LinkedIn](https://linkedin.com/in/yourprofile)
- Email: your.email@example.com

---

## ğŸ“š References

1. Goodfellow, I., et al. (2014). "Generative Adversarial Networks"
2. Arjovsky, M., et al. (2017). "Wasserstein GAN"
3. Gulrajani, I., et al. (2017). "Improved Training of Wasserstein GANs"
4. [Add relevant papers and resources]

---

**â­ If you find this project useful, please consider giving it a star!**
